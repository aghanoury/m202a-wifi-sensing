{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#downloads","title":"Downloads","text":""},{"location":"#abstract","title":"Abstract","text":"<p>Recent studies have developed different sensing applications like human activity recognition (HAR) using WiFi channel state information (CSI) information. However, they usually use high and different sampling rates of CSI, which is impractical and will hurt the communication performance. Besides, different sensing tasks or applications may require different minimum/best sampling rates due to different movement speeds and highest frequency of the activities. E.g, [1] suggests CSI sampling rate should be chosen as 800Hz for HAR, while [2] uses 500Hz and [3] uses 30Hz; [4] chooses 100Hz for indoor crowd counting; [5] exploits 200Hz for sign language recognition; etc. Therefore, it\u2019s interesting to explore different applications\u2019 dependence on sampling rates.</p>"},{"location":"#team","title":"Team","text":"<ul> <li>Emmanuel Magana Mendez</li> <li>Pooya Aghanoury</li> </ul>"},{"location":"#required-submissions","title":"Required Submissions","text":"<ul> <li>Proposal</li> <li>Midterm Checkpoint Presentation Slides</li> <li>Final Presentation Slides</li> <li>Final Report</li> </ul>"},{"location":"proposal/","title":"Project Proposal","text":""},{"location":"proposal/#1-motivation-objective","title":"1. Motivation &amp; Objective","text":"<p>WiFi sensing is a cost-effective and nonintrusive smart sensing solution that utilizes existing WiFi infrastructure. Unlike wearable sensors and camera-based solutions, it offers convenience and overcomes issues like occlusion, poor illumination, and privacy concerns. WiFi sensing has gained attention in ubiquitous computing research and supports applications like activity recognition, gesture recognition, and person identification, thanks to deep neural networks.</p> <p>Because computational power at the edge may be limited, data is better off being transmitted to fog/cloud servers for processing. However, due to high sampling rates and dimensionality of CSI data acquire for HAR, the transmission of this information may seriously impact baseline WiFi performance. There is a need to explore sampling rates lower than the current state of the art. Lower sampling rates generates less data but will require developing new models for training and classification.</p> <p>The goal of this project is to explore the use of various sampling rates for human activity recognition (HAR) using Wifi channel state information (CSI).</p>"},{"location":"proposal/#2-state-of-the-art-its-limitations","title":"2. State of the Art &amp; Its Limitations","text":"<p>The initial project proposal provided some background research which explained that [1] suggests CSI sampling rate should be chosen as 800Hz for HAR as \"typical human movement speed corresponds to CSI components of 300Hz\", while [2] uses 500Hz and [3] uses 30Hz; [4] chooses 100Hz for indoor crowd counting; [5] exploits 200Hz for sign language recognition; etc.</p> <p>Each one of these works makes different claims and assumptions about the rate of human activity movement which necessitates their use of a particular sampling rate. While the literature explores the use of various models, it fails to showcase concrete data on exploring various choices for sampling rate. Therefore, this work aims to explore both of those dimensions.</p>"},{"location":"proposal/#3-novelty-rationale","title":"3. Novelty &amp; Rationale","text":"<p>What is new in your approach and why do you think it will be successful? Our approach will make use of the following datasets: UT_HAR, WIDAR, NTU-Fi_HAR, NTU-Fi_HumanID.</p> <p>We will also be using the following models:MLP,LeNet, ResNet18, ResNet50, ResNet101, RNN, GRU, LSTM, BiLSTM, CNN+GRU, ViT.</p> <p>Each of these datasets has a collection of various labeled and unlabeled samples of human activity at a particular sampling rate (find out which on each is using). One method of exploring other sampling rates would be to downsample a given set, then train our models on that particular set either as it is, or with various types of interpolation.</p>"},{"location":"proposal/#4-potential-impact","title":"4. Potential Impact","text":"<p>If this project is successful, it may serve as the preliminary research needed to explore this topic even further and publish a novel and more efficient methodogoy for HAR via CSI.</p>"},{"location":"proposal/#5-challenges","title":"5. Challenges","text":"<p>The main challenges of this work is not the changing of sampling rates itself, but training new models for classification. We will be constrained on time for this. For example, for every gesture we may want to explore N sampling rates, thus for each of these we may want to then explore M models. Each of these iterations requires significant time and resources for exploration. In general, there will be so many dimensions to our problem search that it might not be possible to explore enough solutions in the time we have.</p>"},{"location":"proposal/#6-requirements-for-success","title":"6. Requirements for Success","text":"<p>To be successful in this project, we will need to have some familiarity (or gain it now!) in deep learning and the necessary frameworks for it's development. We currently have some of this experience.</p>"},{"location":"proposal/#7-metrics-of-success","title":"7. Metrics of Success","text":"<p>We aim to achieve classification performance similar to that found in the literature.</p>"},{"location":"proposal/#8-execution-plan","title":"8. Execution Plan","text":"<p>As it currently stands, we plan to first run trials using the recommended sampling rates and then with either downsampled or upsampled rates and then compare these results. Additionally, we will try different methods of downsampling and upsampling to see if results are different. We will run all the datasets against different models including MLP, LeNET, ResNet, etc.</p> <p>If time permits we will explore what happens if the number of subcarriers change, if a different ML method is used, and using other datasets.</p>"},{"location":"proposal/#9-related-work","title":"9. Related Work","text":""},{"location":"proposal/#9a-papers","title":"9.a. Papers","text":"<p>See the References section below.</p>"},{"location":"proposal/#9b-datasets","title":"9.b. Datasets","text":"<ol> <li>NTU-Fi (HAR, Human ID) [6]</li> <li>UT-HAR, [7]</li> <li>Widar (hand gesture recognition), [8]</li> <li>SignFi, [5]</li> <li>WiAR, [3]</li> <li>Exposing the CSI, [9]</li> <li>RFDataFactory,</li> <li>and other datasets.    List datasets that you have identified and plan to use. Provide references    (with full citation in the References section below).</li> </ol>"},{"location":"proposal/#9c-software","title":"9.c. Software","text":"<p>Python, PyTorch</p>"},{"location":"proposal/#10-references","title":"10. References","text":"<p>List references corresponding to citations in your text above. For papers please include full citation and URL. For datasets and software include name and URL.</p> <p>[1] Wang, Wei, et al. \"Understanding and modeling of wifi signal based human activity recognition.\" MobiCom (2015).</p> <p>[2] Yang, Jianfei, et al. \"EfficientFi: Toward large-scale lightweight WiFi sensing via CSI compression.\" IEEE Internet of Things Journal (2022).</p> <p>[3] Guo, Linlin, et al. \"Wiar: A public dataset for wifi-based activity recognition.\" IEEE Access (2019).</p> <p>[4] Hou, Huawei, et al. \"DASECount: Domain-Agnostic Sample-Efficient Wireless Indoor Crowd Counting via Few-Shot Learning.\" IEEE Internet of Things Journal (2022).</p> <p>[5] Ma, Yongsen, et al. \"SignFi: Sign language recognition using WiFi.\" ACM IMWUT (2018).</p> <p>[6] Yang, Chen, et al. \"SenseFi: A Library and Benchmark on Deep-Learning-Empowered WiFi Human Sensing\", Patterns (2023).</p> <p>[7] Yousefi, Narui, et al. \"A Survey on Behavior Recognition Using WiFi Channel State Information\"IEEE Comunication Magazine (2017)</p> <p>[8] Zheng Yang, Yi Zhang, Guidong Zhang, Yue Zheng, December 26, 2020, \"Widar 3.0: WiFi-based Activity Recognition Dataset\", IEEE Dataport, doi: https://dx.doi.org/10.21227/7znf-qp86.</p> <p>[9] M. Cominelli, F. Gringoli and F. Restuccia, \"Exposing the CSI: A Systematic Investigation of CSI-based Wi-Fi Sensing Capabilities and Limitations,\" 2023 IEEE International Conference on Pervasive Computing and Communications (PerCom), Atlanta, GA, USA, 2023, pp. 81-90, doi: 10.1109/PERCOM56429.2023.10099368.</p>"},{"location":"report/","title":"Report","text":""},{"location":"report/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Table of Contents</li> <li>Abstract</li> <li>1. Introduction</li> <li>2. Background and Related Work</li> <li>3. Technical Approach</li> <li>4. Evaluation and Results</li> <li>5. Discussion and Conclusions</li> <li>6. References</li> </ul>"},{"location":"report/#abstract","title":"Abstract","text":"<p>Recent studies have developed different sensing applications like human activity recognition (HAR) using WiFi channel state information (CSI) information. However, they usually use high and different sampling rates of CSI, which is impractical and will hurt the communication performance. Besides, different sensing tasks or applications may require different minimum/best sampling rates due to different movement speeds and highest frequency of the activities. E.g, [1] suggests CSI sampling rate should be chosen as 800Hz for HAR, while [2] uses 500Hz and [3] uses 30Hz; [4] chooses 100Hz for indoor crowd counting; [5] exploits 200Hz for sign language recognition; etc. Therefore, it\u2019s interesting to explore different applications\u2019 dependence on sampling rates. In this study, we perform a comprehensive analysis of these datasets, changing sampling rate and observing the impact on the accuracy of the model. Our results find that each dataset has ample room to reduce sampling rate without sacrificing accuracy.</p>"},{"location":"report/#1-introduction","title":"1. Introduction","text":"<p>Human Activity Recognition (HAR) is the process of identifying and interpreting the actions and activities performed by humans through the analysis of data collected from various sensors. This includes vision-based methods, Inertial Measurement Units (IMU), microphones, and the focus of this work, Radio Frequency (RF) sensors. In particular, WiFi-based HAR leverages native Multiple Input Multiple Output (MIMO) Channel State Information (CSI) to detect changes in WiFi signal strength. The goal of this research is to concentrate on WiFi-based methods using pre-existing datasets. The primary contribution of this work lies in the discovery that each dataset examined provides significant room for sample reduction without compromising performance. This finding has implications for optimizing data collection and processing in HAR, enhancing its efficiency and practical applicability.</p> <p> Figure 1: An overview of various gestures recognizable from Widar [8] dataset.</p> <p>The initial project proposal provided some background research which explained that [1] suggests CSI sampling rate should be chosen as 800Hz for HAR as \"typical human movement speed corresponds to CSI components of 300Hz\", while [2] uses 500Hz and [3] uses 30Hz; [4] chooses 100Hz for indoor crowd counting; [5] exploits 200Hz for sign language recognition; etc.</p> <p>Each one of these works makes different claims and assumptions about the rate of human activity movement which necessitates their use of a particular sampling rate. While the literature explores the use of various models, it fails to showcase concrete data on exploring various choices for sampling rate. Therefore, this work aims to explore both of those dimensions.</p> <p>The novelty of our project is that, there is not one specific sampling rate that is claimed to be the best. Each research group uses what they consider the best in their case. This results in not having a standardized set to which new researchers can reference that would save them time and effort at the beginning of their research.</p> <p>Our metrics of success are the following: </p> <ol> <li>The first thing we want to show is what happens to the model if we were to change the sampling rate. </li> <li>What happens to the accuracy? </li> <li>Does it depend on the model used?</li> <li>Does it depend on the dataset? </li> </ol> <p>We want to be able to categorize these details because many papers use different sampling rates to essentially do the same thing, identification over WiFi.</p>"},{"location":"report/#2-background-and-related-work","title":"2. Background and Related Work","text":""},{"location":"report/#channel-state-information-csi","title":"Channel State Information (CSI)","text":"<p>The choice of WiFi-based Human Activity Recognition (HAR) is motivated by distinct advantages over traditional camera-based systems. Camera systems, while accurate and deterministic, pose limitations due to their requirement for direct line-of-sight (LOS), raising privacy concerns and potential intentional evasion. In contrast, WiFi, being ubiquitous in indoor settings, offers a compelling alternative for HAR. WiFi-based HAR operates passively, mitigating privacy concerns associated with cameras and eliminating the need for a direct line of sight. This not only addresses privacy issues but also provides a more inclusive and less intrusive method for detecting and interpreting human activities in indoor environments.   Figure 2: On the top: a traditional vision-based tracking system. On the bottom is a WiFi based HAR system.</p> <p>Channel State Information (CSI) is highly preferred over something more general like Received Signal Strength (RSS) for Human Activity Recognition (HAR) due to its capacity to provide a more nuanced and comprehensive depiction of the WiFi environment.  Unlike RSS, which merely averages signal strength across the entire bandwidth, CSI encapsulates the amplitude and phase of each channel. This yields a richer dataset for HAR, essentially creating a detailed \"WiFi Image\" that captures the intricacies of signal propagation. </p>"},{"location":"report/#feature-extraction","title":"Feature Extraction","text":"<p>Feature extraction is a process in which relevant information or features are selected or extracted from raw data to reduce its dimensionality or to transform it into a more suitable format for analysis. It's important because it reduces the dimensionality of data, allowing machine learning algorithms to focus on the most relevant information and improving computational efficiency.  By capturing essential patterns or characteristics, it enhances the performance of models in various domains, such as image recognition, natural language processing, and signal processing.</p>"},{"location":"report/#stft","title":"STFT","text":"<p>In the context of WiFi-based HAR, directly feeding CSI data into a model proves impractical; thus feature extraction is paramount. To this end,  various approaches are employed to enhance the interpretability of the data. One common method, and that which is employed in the UT-HAR dataset [7], involves the application of Short-time Fourier transforms (STFT).  This technique proves useful in finding the distinct phases of movements embedded within the CSI data. </p> <p> Figure 2: Another signal</p>"},{"location":"report/#bvp","title":"BVP","text":"<p>The Widar [3] dataset utilizes the Body-coordinate velocity profile (BVP) as a key component in its analysis. The data processing pipeline involves two major stages following the acquisition of Channel State Information (CSI): first, converting CSI to BVP, and then extracting relevant features from the BVP. The subsequent work involves classifying activities based on this Body-coordinate velocity profile.</p> <p> Figure 3: BVP pipeline from [3]</p>"},{"location":"report/#general-feature-extractions","title":"General Feature Extractions","text":"<p>EfficientFi [2], authored by the creators of SenseFi and NTU datasets, employs a pipeline involving feature extraction directly from raw CSI data. They utilize a quantization method to compress the feature map by mapping measured feature vectors to the nearest vector in a CSI codebook. Classification is performed solely on the extracted features, and a decoder network is employed to store CSI data on the server itself.</p> <p> Figure 4: architecture of NTU-Fi [6]</p>"},{"location":"report/#deep-learning-models","title":"Deep Learning Models","text":"<p>MLP (Multi-Layer Perceptron): Simple and robust architecture, but slow *convergence and significant computational costs are drawbacks.</p> <p>CNN (Convolutional Neural Network): Excels in capturing spatial and temporal features, but may have a limited receptive field due to kernel size and traditionally stacks all feature maps equally.</p> <p>RNN (Recurrent Neural Network): Effective for handling time sequence data like video and Channel State Information (CSI), capable of memorizing arbitrary-length sequences. However, faces challenges in capturing long-term dependencies and suffers from the vanishing gradient problem during backpropagation.</p> <p>LSTM (Long Short-Term Memory): Addresses the vanishing gradient problem in traditional RNNs, allowing better handling of long-term dependencies. However, it introduces increased complexity compared to standard RNNs.</p>"},{"location":"report/#motivation","title":"Motivation","text":"<p>The motivation of previous works in this domain involved modifying the Channel State Information (CSI) at the edge, followed by post-processing, potentially including denoising, and feature extraction using methods like Short-Time Fourier Transform (STFT) and Velocity Profile. The feature data is then offloaded to servers for machine learning classification. The primary goal of this work is to analyze the impact of sampling rate on classification performance, with the potential benefit of minimizing traffic between the edge and the cloud.</p> <p> Figure 5: General WiFi HAR processing architecture with emphasis where our work explores</p>"},{"location":"report/#3-technical-approach","title":"3. Technical Approach","text":"<p>In this work, we make use of several datasets as follows:</p> <ol> <li>UT-HAR [7]: Includes measurements of 7 different activities.</li> <li>NTU-FI [6]: A Human Activity Recognition (HAR) dataset featuring 6 different activities.</li> <li>HumanID: A dataset focused on the gait of 15 individuals.</li> <li>Widar [3]: Comprises a dataset with records of 22 different activities.</li> <li>SignFi [5]: Involves a dataset with 256 different signed symbols.</li> </ol> <p>Furthermore, we build upon the framework from SenseFi [6], which uses Python, Pytorch, and some other works [5] which use Matlab. </p> <p>Lastly, we make use of the following models: - Multi-layer Perceptron (MLP) - Recurrent Neural Network (RNN) - Gated Recurrent Unit (GRU) - Gated Recurrent Unit + Convolutional Neural Network (GRU+CNN) - LeNet (Special Type of CNN) [6] - CNN \u2013 Used in SignFi</p>"},{"location":"report/#summary-of-datasets","title":"Summary of Datasets","text":"Datasets Activities Environment Number of subjects/samples BW Time of Each Activity NTU-Fi-HAR 6: running, walking, falling, boxing, circling arms, cleaning floor Lab 20 people, each activity 20 times 40 MHz 5s NTU-Fi-HumanID 15 people\u2019s gait Lab, 3 scenario 15 people 40 MHz 5s UT-HAR 6: lie down, fall, walk, run, sit down, stand up Office 6 people, 20 trials per activity Data collected continuously 20 MHz 20s Widar 22: Push, Pull,Sweep,Clap,Slide, 18 types of Draws 3 environments: classroom, hall, office 16 volunteers 20 MHz Not Available SignFi 276 signed gestures Lab, home 5 people 20 MHz 2.5s"},{"location":"report/#code","title":"Code","text":"<p>Once the datasets are downloaded, we forked the SenseFi repository and made signifcant modifications to their framework to help address our research questions. Specifically, our code includes approaches to downsampling, matrix reduction, and modifications to alter the number of subcarriers, thus effectively influencing the bandwidth of the data. We explore different downsampling methods, ranging from straightforward matrix reduction techniques\u2014such as selecting every nth column\u2014to utilizing Python's decimate function and implementing custom downsampling functions. Furthermore, our code incorporates considerations for downsampling at different stages of data processing, be it before or after converting the data into tensor format. To enhance our data analysis capabilities, we have also integrated functionality to generate a confusion matrix. Overall, these code implementations contribute to a comprehensive and flexible framework for processing and understanding the intricacies of the datasets in our project.</p> <p>Below is a summary of our methods:</p> <ul> <li> <p>Matrix Reduction:</p> <ul> <li>Taking every second column for half the sampling frequency, every 4th for \u00bc the sampling, etc.</li> <li>Example: x = x[:,::2];</li> </ul> </li> <li> <p>Decimate Function:</p> <ul> <li>Using the decimate function in Python with a specified decimation factor (q=8, zero_phase=True).</li> <li>Example: x = decimate(x, q=8, zero_phase=True)</li> <li>To use this method, we had to include additional code: x=x.copy()</li> <li>This was neccesary because when we used the decimate function, negative strides occur and as of the time of writing this report, PyTorch is not comptabile         with negative strides.</li> <li>Strides are used to access the elements in the tensor.</li> </ul> </li> <li> <p>Custom Downsampling Functions:</p> <ul> <li>Implementing custom downsampling functions.</li> </ul> </li> <li> <p>Different Areas for Downsampling:</p> <ul> <li>Considering downsampling at various stages, such as pre or post converting the data to tensor format.</li> </ul> </li> <li> <p>Confusion Matrix Development:</p> <ul> <li>Adding code to generate a confusion matrix for further data analysis.</li> </ul> </li> <li> <p>Changing the Number of Subcarriers:</p> <ul> <li>Modifying the number of subcarriers, effectively altering the bandwidth.</li> </ul> </li> </ul> <p>These methods collectively address downsampling, matrix reduction, and additional modifications to analyze and manipulate the data effectively in the context of signal processing and machine learning.</p>"},{"location":"report/#4-evaluation-and-results","title":"4. Evaluation and Results","text":"<p>In this section, we will be discussing the results. We saw no difference with how we implemented the downsampling in the final accuracy. However, we did notice that the time to complete training would be servely delayed if we used the decimate function. This is because of the additional line of code needed to correct the negative strides would force the matrix to be reconstructed every single time. So, we used the matrix reduction method to generate results fastest. Additionally, the area of downsampling did not change the end results. So, we could downsample before or after converting the data to tensor format and saw no change in accuracy or runtime. </p> <p> Figure 6: Accuracy vs Frequency plot for NTU-Fi-HAR dataset with various models</p> <p>As can be seen from Figure 6, very little change in accuracy when downsampling; the largest delta being ~5%. The best performing and most robust model was GRU in our experiments.</p> <p> Figure 7: Accuracy vs Frequency plot for NTU-Fi-HumanID dataset with various models</p> <p>As can be seen from Figure 7, there was very little change in accuracy as well when downsampling; the largest delta being ~4%. The best performing and most robust model was again GRU.</p> <p> Figure 8: Accuracy vs Frequency plot for UT-HAR dataset with various models</p> <p>As can be seen from Figure 8, there was more of a change in accuracy when downsampling compared to NTU-Fi-HAR and HumanID datasets; the largest delta being ~10%. However, it was still not a significant decrease. The best performing model here was LeNet, but the most robust was MLP.</p> <p> Figure 9: Accuracy vs Frequency plot for Widar dataset with various models</p> <p>As can be seen from Figure 9, there was a significant decrease in accuracy when downsampling occurred; the largest delta being ~50%. The best performing model here was MLP, but we did not have a robust model since all that were tested experienced similar results.</p> <p> Figure 10: Accuracy vs Frequency plot for SignFi dataset with a CNN model</p> <p>As can be seen from Figure 10, there was also a decrease in accuracy when downsampling. The accuracy would decrease ~10% each time the frequency was downsampled by half. </p>"},{"location":"report/#confusion-matrices","title":"Confusion Matrices","text":"<p>The results above describe the overall accuracy of each dataset and model combination as a function of sampling rate.  However, to gain a more detailed understanding of the tracking of each activity, we also generated confusion matrices for each dataset and model combination.</p> <p>Interestingly, we observe accross the board that the accuracy per task is relatively consistent accross the sampling rates explored in this work. This is likely due to the fact that the activities are relatively distinct from one another, and thus the model is able to distinguish between them even with reduced sampling rates. </p> <p>For example, in UT-HAR we see that the model is able to distinguish between the \"Lie Down\" and \"Fall\" activities with high accuracy, even at the lowest sampling rate of 50 Hz. This is likely due to the fact that the \"Lie Down\" activity is a relatively static activity, while the \"Fall\" activity is a dynamic activity. Thus, the model is able to distinguish between the two activities even with reduced sampling rates.</p> <p>Furthermore, in NTU-Fi-HAR we see that the model is able to distinguish between the \"Run\" and \"Walk\" activities with high accuracy. This is likely due to the fact that the \"Run\" activity is much faster periodically relative to a  \"Walk\" activity.</p> <p>And lastly, in NTU-Fi-HumanID we see that the model is able to distinguish between the specific individuals with high accuracy. This is likely due to the fact that the gait of each individual is unique enough to provide proper classification. </p> <p>The resulting confusion matrices are shown below.</p>"},{"location":"report/#ut-har","title":"UT-HAR","text":"Code Activity 0 Lie down 1 Fall 2 Walk 3 Pick up 4 Run 5 Sit down 6 Stand up <p> Figure 11: Confusion Matrix for UT-HAR dataset with GRU model and 250 Hz sampling rate</p> <p> Figure 12: Confusion Matrix for UT-HAR dataset with GRU model and 125 Hz sampling rate</p> <p> Figure 13: Confusion Matrix for UT-HAR dataset with GRU model and 50 Hz sampling rate</p>"},{"location":"report/#ntu-fi-har","title":"NTU-Fi-HAR","text":"Code Object 0 Box 1 Circle 2 Clean 3 Fall 4 Walk 5 Run <p> Figure 14: Confusion Matrix for NTU-Fi-HAR dataset with GRU model and 500 Hz sampling rate</p> <p> Figure 15: Confusion Matrix for NTU-Fi-HAR dataset with GRU model and 250 Hz sampling rate</p> <p> Figure 16: Confusion Matrix for NTU-Fi-HAR dataset with GRU model and 125 Hz sampling rate</p>"},{"location":"report/#ntu-fi-humanid","title":"NTU-Fi-HumanID","text":"<p> Figure 17: Confusion Matrix for NTU-Fi-HumanID dataset with GRU model and 500 Hz sampling rate</p> <p> Figure 18: Confusion Matrix for NTU-Fi-HumanID dataset with GRU model and 250 Hz sampling rate</p> <p> Figure 19: Confusion Matrix for NTU-Fi-HumanID dataset with GRU model and 125 Hz sampling rate</p>"},{"location":"report/#5-discussion-and-conclusions","title":"5. Discussion and Conclusions","text":"<p>From our results, we can see that datasets that had less activities would be less affected by downsampling. NTU-Fi-HAR had 6 activities but only two of them were similar. This explains why the accuracy did drop slightly with downsampling but not much overall. NTU-Fi-HumanID had 15 \"activites\" each representing the gait of distinct individuals. The accuracy changed very little as well because the gait of an individual can be unique enough to provide proper classification. UT-HAR had 7 activities and did see more of a decrease in accuracy when compared to NTU-Fi datasets. This is because UT-HAR had 2 pairs of activites that were similar that when downsampling could be potentially misclassified resulting in the decrease in accuracy we saw. Widar and SignFi had the largest decrease in accuracy because those two had more similar activites. Widar dataset is composed of 22 activites, 18 of which draws using hands, and SignFi dataset has 276 signed gestures. When downsampling, the information to properly classify the hand gestures or draws could have been lost or not enough information was present to properly classify the signs. </p> <p>Additionally, we saw some interesting results that should be explored further. When comparing the datasets and how they were structured, we noticed that the ones that were composed of only the amplitude component of the CSI data performed better. This included NTU-Fi datasets and the UT-HAR dataset. In contrast, the datasets composed of both the amplitude and phase component performed worse. SignFi directly used the amplitude and phase components in it's code and Widar dataset was composed of BVP which are derived from the amplitude and phase. This should be explored further to rule out as a contributing factor.</p> <p>Also, changing the subcarriers used did affect the accuracy. We conducted an experiment where we divided the subcarriers into even groups of 3. When the second and thrid group were used, the accuracy would be around the same as if we used the entire set of subcarriers. However, when we used the first group, the accuracy decreased about 20-30%. Due to time constraint and this being out of scope of the project, we could not dive more into this but it should also be explored further. The accuracy did not change if we kept the same subcarrier group constant but downsampled. </p> <p>Overall, we succeeded in identifying the effect of downsampling on the accuracy of WiFi sensing for various models and datasets that contained many different activites. We also indentified potential areas for future work.</p> <p>First, it would be interesting to explore downsampling the raw data. This project focused on the downsampling pre-processed data. But what would happen if the downsampling occured on the raw data? Would the results be any different? Also, if you processed the downsampled raw data would it match the downsampled pre-processed data from this experiment?</p> <p>Second, the subcarrier selection should be explored further; it seemed to be headed to some interesting results. Third, explore various models and architectures. Fourth, explore using multi-modal HAR like combining multiple data sets/sensors. Lastly, exploring which activities require CSI amplitude for proper classification vs which require amplitude and phase. This should be explored only if the correlation that we noticed is confirmed.</p> <p>Lastly, we did face some challenges throughout the project. </p> <p>1) Both of us had lack of experience with different models of machine learning so we had to understand those better.  2) Comparing multiple datasets in this context is a challenge due to the sheer number of variables and overall differences between the compositions of the data and the activities they\u2019re measuring. 3) Finding computational resources took some initial time. We ran into memory issues because others were also using it to train their own models for other tasks. 4) Understanding the various ways datasets were normalized.</p> <p>We would like to thank Professor Mani Srivastava and Gaofeng Dong for their support and guidance throughout this project.</p>"},{"location":"report/#6-references","title":"6. References","text":"<p>[1] Wang, Wei, et al. \"Understanding and modeling of wifi signal based human activity recognition.\" MobiCom (2015).</p> <p>[2] Yang, Jianfei, et al. \"EfficientFi: Toward large-scale lightweight WiFi sensing via CSI compression.\" IEEE Internet of Things Journal (2022).</p> <p>[3] Guo, Linlin, et al. \"Wiar: A public dataset for wifi-based activity recognition.\" IEEE Access (2019).</p> <p>[4] Hou, Huawei, et al. \"DASECount: Domain-Agnostic Sample-Efficient Wireless Indoor Crowd Counting via Few-Shot Learning.\" IEEE Internet of Things Journal (2022).</p> <p>[5] Ma, Yongsen, et al. \"SignFi: Sign language recognition using WiFi.\" ACM IMWUT (2018).</p> <p>[6] Yang, Chen, et al. \"SenseFi: A Library and Benchmark on Deep-Learning-Empowered WiFi Human Sensing\", Patterns (2023).</p> <p>[7] Yousefi, Narui, et al. \"A Survey on Behavior Recognition Using WiFi Channel State Information\"IEEE Comunication Magazine (2017)</p> <p>[8] Zheng Yang, Yi Zhang, Guidong Zhang, Yue Zheng, December 26, 2020, \"Widar 3.0: WiFi-based Activity Recognition Dataset\", IEEE Dataport, doi: https://dx.doi.org/10.21227/7znf-qp86.</p> <p>[9] M. Cominelli, F. Gringoli and F. Restuccia, \"Exposing the CSI: A Systematic Investigation of CSI-based Wi-Fi Sensing Capabilities and Limitations,\" 2023 IEEE International Conference on Pervasive Computing and Communications (PerCom), Atlanta, GA, USA, 2023, pp. 81-90, doi: 10.1109/PERCOM56429.2023.10099368.</p> <p>[10] https://wirelesspi.com/advantages-and-disadvantages-of-ofdm-a-summary/</p> <p>[11] From Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, \u201cGradient-based learning applied to document recognition,\u201dProceedings of the IEEE, vol.86,no.11,pp.2278\u20132324,1998.</p> <p>[12] Sim JM, Lee Y, Kwon O. Acoustic Sensor Based Recognition of Human Activity in Everyday Life for Smart Home Services. International Journal of Distributed Sensor Networks. 2015;11(9). doi:10.1155/2015/679123</p>"},{"location":"media/","title":"Index","text":"<p>Put any image, video, sound, and such files here.</p>"}]}